{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import open_clip\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration class\n",
    "class Config:\n",
    "    batch_size = 32\n",
    "    learning_rate = 2e-5\n",
    "    epochs = 5\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_name = \"hf-hub:imageomics/bioclip\"\n",
    "    num_classes = 0\n",
    "    image_size = 224\n",
    "    top_k = 10\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FungiTastic(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for the FewShot subset of the Danish Fungi dataset (size 300, closed-set).\n",
    "\n",
    "    This dataset loader supports training, validation, and testing splits, and provides\n",
    "    convenient access to images, class IDs, and file paths. It also supports optional\n",
    "    image transformations.\n",
    "    \"\"\"\n",
    "\n",
    "    SPLIT2STR = {'train': 'Train', 'val': 'Val', 'test': 'Test'}\n",
    "\n",
    "    def __init__(self, root: str, split: str = 'val', transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the FungiTastic dataset.\n",
    "\n",
    "        Args:\n",
    "            root (str): The root directory of the dataset.\n",
    "            split (str, optional): The dataset split to use. Must be one of {'train', 'val', 'test'}.\n",
    "                Defaults to 'val'.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.df = self._get_df(root, split)\n",
    "        self.feature_df = self.df.copy()\n",
    "        self.feature_selection = ['year', 'month', 'habitat', 'country_code', 'iucnRedListCategory', 'substrate', 'coorUncert', 'latitude', 'longitude', 'region', 'district', 'poisonous', 'elevation', 'landcover', 'biogeographicalRegion']\n",
    "\n",
    "        assert \"image_path\" in self.df\n",
    "        if self.split != 'test':\n",
    "            assert \"category_id\" in self.df\n",
    "            self.n_classes = len(self.df['category_id'].unique())\n",
    "            self.category_id2label = {\n",
    "                k: v[0] for k, v in self.df.groupby('category_id')['species'].unique().to_dict().items()\n",
    "            }\n",
    "            self.label2category_id = {\n",
    "                v: k for k, v in self.category_id2label.items()\n",
    "            }\n",
    "        else:\n",
    "            # For test set, we need to load category IDs from training set\n",
    "            train_df = self._get_df(root, 'train')\n",
    "            self.n_classes = len(train_df['category_id'].unique())\n",
    "            self.category_id2label = {\n",
    "                k: v[0] for k, v in train_df.groupby('category_id')['species'].unique().to_dict().items()\n",
    "            }\n",
    "            self.label2category_id = {\n",
    "                v: k for k, v in self.category_id2label.items()\n",
    "            }\n",
    "\n",
    "    def add_embeddings(self, embeddings: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Updates the dataset instance with new embeddings.\n",
    "\n",
    "        Args:\n",
    "            embeddings (pd.DataFrame): A DataFrame containing an 'embedding' column.\n",
    "                                       It must align with `self.df` in terms of indexing.\n",
    "        \"\"\"\n",
    "        assert isinstance(embeddings, pd.DataFrame), \"Embeddings must be a pandas DataFrame.\"\n",
    "        assert \"embedding\" in embeddings.columns, \"Embeddings DataFrame must have an 'embedding' column.\"\n",
    "        assert len(embeddings) == len(self.df), \"Embeddings must match dataset length.\"\n",
    "\n",
    "        self.df = pd.merge(self.df, embeddings, on=\"filename\", how=\"inner\")\n",
    "\n",
    "    def get_embeddings_for_class(self, id):\n",
    "        # return the embeddings for class class_idx\n",
    "        class_idxs = self.df[self.df['category_id'] == id].index\n",
    "        return self.df.iloc[class_idxs]['embedding']\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_df(data_path: str, split: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Loads the dataset metadata as a pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data_path (str): The root directory where the dataset is stored.\n",
    "            split (str): The dataset split to load. Must be one of {'train', 'val', 'test'}.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing metadata and file paths for the split.\n",
    "        \"\"\"\n",
    "        df_path = os.path.join(\n",
    "            data_path,\n",
    "            \"metadata\",\n",
    "            \"FungiTastic-FewShot\",\n",
    "            f\"FungiTastic-FewShot-{FungiTastic.SPLIT2STR[split]}.csv\"\n",
    "        )\n",
    "        df = pd.read_csv(df_path)\n",
    "        df[\"image_path\"] = df.filename.apply(\n",
    "            lambda x: os.path.join(data_path, \"FungiTastic-FewShot\", split, '300p', x)\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"\n",
    "        Retrieves a single data sample by index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, category_id, file_path, observation_id, embedding)\n",
    "        \"\"\"\n",
    "        file_path = self.df[\"image_path\"].iloc[idx].replace('FungiTastic-FewShot', 'images/FungiTastic-FewShot')\n",
    "        \n",
    "        # Get observationID if available\n",
    "        observation_id = self.df[\"observationID\"].iloc[idx] if \"observationID\" in self.df.columns else None\n",
    "\n",
    "        if self.split != 'test':\n",
    "            category_id = self.df[\"category_id\"].iloc[idx]\n",
    "        else:\n",
    "            category_id = None  # For test set, no ground truth\n",
    "\n",
    "        image = Image.open(file_path).convert('RGB')  # Ensure RGB format\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, category_id, file_path, observation_id\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "\n",
    "    def get_class_id(self, idx: int) -> int:\n",
    "        \"\"\"\n",
    "        Returns the class ID of a specific sample.\n",
    "        \"\"\"\n",
    "        if \"category_id\" in self.df.columns:\n",
    "            return self.df[\"category_id\"].iloc[idx]\n",
    "        return None\n",
    "\n",
    "    def show_sample(self, idx: int) -> None:\n",
    "        \"\"\"\n",
    "        Displays a sample image along with its class name and index.\n",
    "        \"\"\"\n",
    "        image, category_id, _, _, _ = self.__getitem__(idx)\n",
    "        class_name = self.category_id2label[category_id] if category_id is not None else \"Unknown\"\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Class: {class_name}; id: {idx}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def get_category_idxs(self, category_id: int) -> List[int]:\n",
    "        \"\"\"\n",
    "        Retrieves all indexes for a given category ID.\n",
    "        \"\"\"\n",
    "        if \"category_id\" in self.df.columns:\n",
    "            return self.df[self.df.category_id == category_id].index.tolist()\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FungiEmbedder(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper for extracting image embeddings using a pre-trained visual model.\n",
    "    Most layers are frozen except the final two transformer blocks.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if \"visual.transformer.resblocks.11\" not in name and \"visual.transformer.resblocks.10\" not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "       return self.model.encode_image(pixel_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Prototypical loss that computes classification loss based on distances\n",
    "    between input embeddings and class prototypes.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, embeddings, targets, prototypes):\n",
    "        dists = torch.cdist(embeddings, prototypes, p=2)\n",
    "        logits = -dists\n",
    "        loss = nn.functional.cross_entropy(logits, targets)\n",
    "        return loss, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_prototypes(model, dataloader, device, num_classes):\n",
    "    \"\"\"\n",
    "    Compute class prototypes by averaging embeddings from support samples\n",
    "    for each class in the dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_embeddings = [[] for _ in range(num_classes)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Extracting Prototypes\"):\n",
    "            images, labels, _, _ = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            embeddings = model(images)\n",
    "            for emb, label in zip(embeddings, labels):\n",
    "                all_embeddings[label.item()].append(emb.cpu())\n",
    "\n",
    "    prototypes = []\n",
    "    for class_embs in all_embeddings:\n",
    "        if len(class_embs) == 0:\n",
    "            prototypes.append(torch.zeros_like(embeddings[0]))\n",
    "        else:\n",
    "            prototypes.append(torch.stack(class_embs).mean(dim=0))\n",
    "\n",
    "    return torch.stack(prototypes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_protonet(model, dataloader, criterion, optimizer, device, prototypes):\n",
    "    \"\"\"\n",
    "    Train one epoch using Prototypical Network logic.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, labels, _, _ = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        embeddings = model(images)\n",
    "        loss, logits = criterion(embeddings, labels, prototypes)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    return epoch_loss / len(dataloader), accuracy, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Prototypes: 100%|██████████| 245/245 [01:21<00:00,  3.01it/s]\n"
     ]
    }
   ],
   "source": [
    "data_root = \"data/fungi-clef-2025\"\n",
    "\n",
    "# Load BioCLIP model and preprocessing function\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(config.model_name)\n",
    "embedder = FungiEmbedder(model).to(config.device)\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = FungiTastic(root=data_root, split='train', transform=preprocess)\n",
    "val_dataset = FungiTastic(root=data_root, split='val', transform=preprocess)\n",
    "test_dataset = FungiTastic(root=data_root, split='test', transform=preprocess)\n",
    "\n",
    "config.num_classes = train_dataset.n_classes\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Initialize loss function and optimizer\n",
    "criterion = PrototypicalLoss()\n",
    "optimizer = torch.optim.AdamW(embedder.parameters(), lr=config.learning_rate)\n",
    "\n",
    "# Compute class prototypes from training data\n",
    "prototypes = compute_prototypes(embedder, train_loader, config.device, config.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 245/245 [02:05<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.2607, Acc: 0.9178, F1: 0.9503\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 245/245 [01:56<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.0199, Acc: 0.9387, F1: 0.9629\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 245/245 [01:46<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.8625, Acc: 0.9561, F1: 0.9739\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 245/245 [01:37<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.7289, Acc: 0.9690, F1: 0.9814\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 245/245 [01:37<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.6162, Acc: 0.9802, F1: 0.9879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(config.epochs):\n",
    "    print(f\"Epoch {epoch+1}/{config.epochs}\")\n",
    "    train_loss, train_acc, train_f1 = train_epoch_protonet(embedder, train_loader, criterion, optimizer, config.device, prototypes)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for test dataloader,\n",
    "    allows category_id to be None.\n",
    "    \"\"\"\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "    labels = [item[1] for item in batch]  # will be all None\n",
    "    file_paths = [item[2] for item in batch]\n",
    "    observation_ids = [item[3] for item in batch]\n",
    "    return images, labels, file_paths, observation_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=test_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_protonet_grouped(model, dataloader, prototypes, device, dataset, k=10, save_path=\"test_predictions.csv\"):\n",
    "    \"\"\"\n",
    "    Evaluate using prototype similarity and group predictions by observation ID.\n",
    "    Aggregates predictions per observation using mean pooling.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        model: FungiEmbedder\n",
    "        dataloader: test dataloader\n",
    "        prototypes: tensor [num_classes, embedding_dim]\n",
    "        device: cuda/cpu\n",
    "        dataset: FungiTastic (for ID mapping)\n",
    "        k: number of top predictions\n",
    "        save_path: CSV save path\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    observation_logits = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images, _, _, observation_ids = batch\n",
    "            images = images.to(device)\n",
    "            embeddings = model(images)\n",
    "            dists = torch.cdist(embeddings, prototypes, p=2)  # [B, C]\n",
    "            probs = -dists  # higher is better\n",
    "\n",
    "            probs = probs.cpu().numpy()\n",
    "            for i, obs_id in enumerate(observation_ids):\n",
    "                if obs_id not in observation_logits:\n",
    "                    observation_logits[obs_id] = []\n",
    "                observation_logits[obs_id].append(probs[i])\n",
    "\n",
    "    # Aggregate per observation\n",
    "    results = []\n",
    "    for obs_id, logits_list in observation_logits.items():\n",
    "        avg_logits = np.mean(logits_list, axis=0)\n",
    "        topk = np.argsort(avg_logits)[-k:][::-1]\n",
    "        predictions = ' '.join(str(c) for c in topk)\n",
    "        results.append({'ObservationId': obs_id, 'predictions': predictions})\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved grouped prediction results to {save_path}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 60/60 [00:20<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved grouped prediction results to results/test_predictions_protoNet_grouped.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObservationId</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4100099350</td>\n",
       "      <td>2041 2272 1418 138 1797 1393 2120 10 1438 613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4100096393</td>\n",
       "      <td>2028 2119 62 2383 671 859 578 663 672 1637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4100103428</td>\n",
       "      <td>1278 15 737 16 961 1388 1850 434 1281 735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4100096438</td>\n",
       "      <td>224 946 1059 259 947 2267 1646 253 1422 40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4100102708</td>\n",
       "      <td>928 929 1696 1693 1264 382 1398 660 2175 613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>4465903547</td>\n",
       "      <td>1339 1627 245 795 2299 900 877 1469 910 203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4465903708</td>\n",
       "      <td>651 2136 877 875 1203 1095 1093 2204 1339 1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>4465903714</td>\n",
       "      <td>618 617 1048 1566 1194 1540 627 365 1044 1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4465903823</td>\n",
       "      <td>2119 1491 672 726 589 1693 304 929 1649 671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4847338798</td>\n",
       "      <td>1500 1838 284 130 2383 1336 438 347 2040 1660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ObservationId                                     predictions\n",
       "0       4100099350   2041 2272 1418 138 1797 1393 2120 10 1438 613\n",
       "1       4100096393      2028 2119 62 2383 671 859 578 663 672 1637\n",
       "2       4100103428       1278 15 737 16 961 1388 1850 434 1281 735\n",
       "3       4100096438      224 946 1059 259 947 2267 1646 253 1422 40\n",
       "4       4100102708    928 929 1696 1693 1264 382 1398 660 2175 613\n",
       "..             ...                                             ...\n",
       "994     4465903547     1339 1627 245 795 2299 900 877 1469 910 203\n",
       "995     4465903708  651 2136 877 875 1203 1095 1093 2204 1339 1020\n",
       "996     4465903714   618 617 1048 1566 1194 1540 627 365 1044 1446\n",
       "997     4465903823     2119 1491 672 726 589 1693 304 929 1649 671\n",
       "998     4847338798   1500 1838 284 130 2383 1336 438 347 2040 1660\n",
       "\n",
       "[999 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_protonet_grouped(\n",
    "    model=embedder,\n",
    "    dataloader=test_loader,\n",
    "    prototypes=prototypes,\n",
    "    device=config.device,\n",
    "    dataset=test_dataset,\n",
    "    k=config.top_k,\n",
    "    save_path=\"results/test_predictions_protoNet_grouped.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_protonet_maxpool(model, dataloader, prototypes, device, dataset, k=10, save_path=\"test_predictions.csv\"):\n",
    "    \"\"\"\n",
    "    Evaluate using prototype similarity and group predictions by observation ID.\n",
    "    Aggregates predictions per observation using max pooling.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    observation_logits = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images, _, _, observation_ids = batch\n",
    "            images = images.to(device)\n",
    "            embeddings = model(images)\n",
    "            dists = torch.cdist(embeddings, prototypes, p=2)\n",
    "            probs = -dists  # higher is better\n",
    "            probs = probs.cpu().numpy()\n",
    "\n",
    "            for i, obs_id in enumerate(observation_ids):\n",
    "                if obs_id not in observation_logits:\n",
    "                    observation_logits[obs_id] = []\n",
    "                observation_logits[obs_id].append(probs[i])\n",
    "\n",
    "    results = []\n",
    "    for obs_id, logits_list in observation_logits.items():\n",
    "        max_logits = np.max(logits_list, axis=0)  # max-pooling across images\n",
    "        topk = np.argsort(max_logits)[-k:][::-1]\n",
    "        predictions = ' '.join(str(c) for c in topk)\n",
    "        results.append({'ObservationId': obs_id, 'predictions': predictions})\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved max-pooled prediction results to {save_path}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 60/60 [00:23<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved max-pooled prediction results to results/test_predictions_protoNet_maxpool.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObservationId</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4100099350</td>\n",
       "      <td>2041 2272 1418 138 1797 1393 2120 10 1438 613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4100096393</td>\n",
       "      <td>2028 2119 62 2383 671 859 578 663 672 1637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4100103428</td>\n",
       "      <td>15 1278 737 16 1850 735 398 1388 1288 1579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4100096438</td>\n",
       "      <td>224 946 1059 259 947 2267 1646 253 1422 40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4100102708</td>\n",
       "      <td>928 929 1696 1693 1264 382 1398 660 2175 613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>4465903547</td>\n",
       "      <td>1339 1627 245 795 2299 900 877 1469 910 203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4465903708</td>\n",
       "      <td>651 2136 877 875 1203 1095 1093 2204 1339 1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>4465903714</td>\n",
       "      <td>618 617 1048 1566 1194 1540 627 365 1044 1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4465903823</td>\n",
       "      <td>2119 672 1491 726 1300 1649 671 589 242 675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4847338798</td>\n",
       "      <td>1500 1838 284 130 2383 1336 438 347 2040 1660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ObservationId                                     predictions\n",
       "0       4100099350   2041 2272 1418 138 1797 1393 2120 10 1438 613\n",
       "1       4100096393      2028 2119 62 2383 671 859 578 663 672 1637\n",
       "2       4100103428      15 1278 737 16 1850 735 398 1388 1288 1579\n",
       "3       4100096438      224 946 1059 259 947 2267 1646 253 1422 40\n",
       "4       4100102708    928 929 1696 1693 1264 382 1398 660 2175 613\n",
       "..             ...                                             ...\n",
       "994     4465903547     1339 1627 245 795 2299 900 877 1469 910 203\n",
       "995     4465903708  651 2136 877 875 1203 1095 1093 2204 1339 1020\n",
       "996     4465903714   618 617 1048 1566 1194 1540 627 365 1044 1446\n",
       "997     4465903823     2119 672 1491 726 1300 1649 671 589 242 675\n",
       "998     4847338798   1500 1838 284 130 2383 1336 438 347 2040 1660\n",
       "\n",
       "[999 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_protonet_maxpool(embedder, test_loader, prototypes, config.device, test_dataset, k=config.top_k, save_path=\"results/test_predictions_protoNet_maxpool.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def evaluate_protonet_voting(model, dataloader, prototypes, device, dataset, k=10, save_path=\"test_predictions_voting.csv\"):\n",
    "    \"\"\"\n",
    "    Evaluate model with voting-based aggregation across multiple images per observation.\n",
    "    \n",
    "    Args:\n",
    "        model: trained embedder\n",
    "        dataloader: test dataloader\n",
    "        prototypes: class prototype embeddings\n",
    "        device: torch.device\n",
    "        dataset: FungiTastic dataset (for Observation IDs)\n",
    "        k: number of top classes to return\n",
    "        save_path: CSV file to write predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    observation_votes = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating (Voting)\"):\n",
    "            images, _, _, observation_ids = batch\n",
    "            images = images.to(device)\n",
    "            embeddings = model(images)\n",
    "            dists = torch.cdist(embeddings, prototypes, p=2)  # [B, C]\n",
    "            logits = -dists\n",
    "            preds = torch.topk(logits, k=k, dim=1).indices.cpu().numpy()  # [B, k]\n",
    "\n",
    "            for i, obs_id in enumerate(observation_ids):\n",
    "                if obs_id not in observation_votes:\n",
    "                    observation_votes[obs_id] = []\n",
    "                observation_votes[obs_id].extend(preds[i].tolist())\n",
    "\n",
    "    # Aggregate by majority voting\n",
    "    results = []\n",
    "    for obs_id, votes in observation_votes.items():\n",
    "        vote_count = Counter(votes)\n",
    "        topk = [cls_id for cls_id, _ in vote_count.most_common(k)]\n",
    "        # pad if not enough classes\n",
    "        if len(topk) < k:\n",
    "            topk += [topk[-1]] * (k - len(topk))\n",
    "        prediction_str = ' '.join(str(c) for c in topk)\n",
    "        results.append({'ObservationId': obs_id, 'predictions': prediction_str})\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved voting-based predictions to {save_path}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (Voting): 100%|██████████| 60/60 [00:19<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved voting-based predictions to results/test_predictions_protoNet_voting.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObservationId</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4100099350</td>\n",
       "      <td>2041 2272 1418 138 1797 1393 2120 10 1438 613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4100096393</td>\n",
       "      <td>2028 2119 62 2383 671 859 578 663 672 1637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4100103428</td>\n",
       "      <td>15 1278 1281 737 961 1388 13 1288 1386 1277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4100096438</td>\n",
       "      <td>224 946 1059 259 947 2267 1646 253 1422 40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4100102708</td>\n",
       "      <td>928 929 1696 1693 1264 382 1398 660 2175 613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>4465903547</td>\n",
       "      <td>1339 1627 245 795 2299 900 877 1469 910 203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4465903708</td>\n",
       "      <td>651 2136 877 875 1203 1095 1093 2204 1339 1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>4465903714</td>\n",
       "      <td>618 617 1048 1566 1194 1540 627 365 1044 1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4465903823</td>\n",
       "      <td>2119 1491 726 672 1300 671 589 675 613 660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4847338798</td>\n",
       "      <td>1500 1838 284 130 2383 1336 438 347 2040 1660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ObservationId                                     predictions\n",
       "0       4100099350   2041 2272 1418 138 1797 1393 2120 10 1438 613\n",
       "1       4100096393      2028 2119 62 2383 671 859 578 663 672 1637\n",
       "2       4100103428     15 1278 1281 737 961 1388 13 1288 1386 1277\n",
       "3       4100096438      224 946 1059 259 947 2267 1646 253 1422 40\n",
       "4       4100102708    928 929 1696 1693 1264 382 1398 660 2175 613\n",
       "..             ...                                             ...\n",
       "994     4465903547     1339 1627 245 795 2299 900 877 1469 910 203\n",
       "995     4465903708  651 2136 877 875 1203 1095 1093 2204 1339 1020\n",
       "996     4465903714   618 617 1048 1566 1194 1540 627 365 1044 1446\n",
       "997     4465903823      2119 1491 726 672 1300 671 589 675 613 660\n",
       "998     4847338798   1500 1838 284 130 2383 1336 438 347 2040 1660\n",
       "\n",
       "[999 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_protonet_voting(\n",
    "    model=embedder,\n",
    "    dataloader=test_loader,\n",
    "    prototypes=prototypes,\n",
    "    device=config.device,\n",
    "    dataset=test_dataset,\n",
    "    k=config.top_k,\n",
    "    save_path=\"results/test_predictions_protoNet_voting.csv\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (p3-env)",
   "language": "python",
   "name": "p3-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
